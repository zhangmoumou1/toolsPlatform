import asyncio
from mimetypes import guess_type
from os.path import isfile

from apscheduler.jobstores.sqlalchemy import SQLAlchemyJobStore
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from fastapi import Request, WebSocket, WebSocketDisconnect, Depends
from starlette.responses import Response
from starlette.staticfiles import StaticFiles
from starlette.templating import Jinja2Templates

from app.routers.others import router as others_router

from app import qms, init_logging
from app.crud import create_table
from app.middleware.RedisManager import RedisHelper
from config import Config, QMS_ENV, BANNER

logger = init_logging()

logger.bind(name=None).opt(ansi=True).success(f"qms is running at <red>{QMS_ENV}</red>")
logger.bind(name=None).success(BANNER)


async def request_info(request: Request):
    logger.bind(name=None).debug(f"{request.method} {request.url}")
    try:
        body = await request.json()
        logger.bind(payload=body, name=None).debug("request_json: ")
    except:
        try:
            body = await request.body()
            if len(body) != 0:
                # æœ‰è¯·æ±‚ä½“ï¼Œè®°å½•æ—¥å¿—
                logger.bind(payload=body, name=None).debug(body)
        except:
            # å¿½ç•¥æ–‡ä»¶ä¸Šä¼ ç±»å‹çš„æ•°æ®
            pass

# æ³¨å†Œè·¯ç”±
qms.include_router(others_router)


@qms.get("/{filename}")
async def get_site(filename):
    filename = './statics/' + filename

    if not isfile(filename):
        return Response(status_code=404)

    with open(filename, mode='rb') as f:
        content = f.read()

    content_type, _ = guess_type(filename)
    return Response(content, media_type=content_type)


@qms.get("/static/{filename}")
async def get_site_static(filename):
    filename = './statics/static/' + filename

    if not isfile(filename):
        return Response(status_code=404)

    with open(filename, mode='rb') as f:
        content = f.read()

    content_type, _ = guess_type(filename)
    return Response(content, media_type=content_type)


@qms.on_event('startup')
async def init_redis():
    """
    åˆå§‹åŒ–redisï¼Œå¤±è´¥åˆ™æœåŠ¡èµ·ä¸æ¥
    :return:
    """
    try:
        await RedisHelper.ping()
        logger.bind(name=None).success("redis connected success.        âœ”")
    except Exception as e:
        if not Config.REDIS_ON:
            logger.bind(name=None).warning(
                f"Redis is not selected, So we can't ensure that the task is not executed repeatedly.        ğŸš«")
            return
        logger.bind(name=None).error(f"Redis connect failed, Please check config.py for redis config.        âŒ")
        raise e


# @pity.on_event('startup')
# def init_scheduler():
#     """
#     åˆå§‹åŒ–å®šæ—¶ä»»åŠ¡
#     :return:
#     """
#     # SQLAlchemyJobStoreæŒ‡å®šå­˜å‚¨é“¾æ¥
#     job_store = {
#         'default': SQLAlchemyJobStore(url=Config.SQLALCHEMY_DATABASE_URI, engine_options={"pool_recycle": 1500},
#                                       pickle_protocol=3)
#     }
#     scheduler = AsyncIOScheduler()
#     Scheduler.init(scheduler)
#     Scheduler.configure(jobstores=job_store)
#     Scheduler.start()
#     logger.bind(name=None).success("ApScheduler started success.        âœ”")


@qms.on_event('startup')
async def init_database():
    """
    åˆå§‹åŒ–æ•°æ®åº“ï¼Œå»ºè¡¨
    :return:
    """
    try:
        asyncio.create_task(create_table())
        logger.bind(name=None).success("database and tables created success.        âœ”")
    except Exception as e:
        logger.bind(name=None).error(f"database and tables  created failed.        âŒ\nerror: {e}")
        raise


@qms.on_event('shutdown')
def stop_test():
    pass


# @pity.websocket("/ws/{user_id}")
# async def websocket_endpoint(websocket: WebSocket, user_id: int):
#     async def send_heartbeat():
#         while True:
#             logger.debug("sending heartbeat")
#             await websocket.send_json({
#                 'type': 3
#             })
#             await asyncio.sleep(Config.HEARTBEAT)
#
#     await ws_manage.connect(websocket, user_id)
#     try:
#         # å®šä¹‰ç‰¹æ®Šå€¼çš„å›å¤ï¼Œé…åˆå‰ç«¯å®ç°ç¡®å®šè¿æ¥ï¼Œå¿ƒè·³æ£€æµ‹ç­‰é€»è¾‘
#         questions_and_answers_map: dict = {
#             "HELLO SERVER": F"hello {user_id}",
#             "HEARTBEAT": F"{user_id}",
#         }
#
#         # å­˜å‚¨è¿æ¥åè·å–æ¶ˆæ¯
#         msg_records = await PityNotificationDao.list_messages(msg_type=MessageTypeEnum.all.value, receiver=user_id,
#                                                               msg_status=MessageStateEnum.unread.value)
#         # å¦‚æœæœ‰æœªè¯»æ¶ˆæ¯, åˆ™æ¨é€ç»™å‰ç«¯å¯¹åº”çš„count
#         if len(msg_records) > 0:
#             await websocket.send_json(WebSocketMessage.msg_count(len(msg_records), True))
#         # å‘é€å¿ƒè·³åŒ…
#         # asyncio.create_task(send_heartbeat())
#         while True:
#             data: str = await websocket.receive_text()
#             du = data.upper()
#             if du in questions_and_answers_map:
#                 await ws_manage.send_personal_message(message=questions_and_answers_map.get(du), websocket=websocket)
#     except WebSocketDisconnect:
#         if user_id in ws_manage.active_connections:
#             ws_manage.disconnect(user_id)
#     except Exception as e:
#         logger.bind(name=None).debug(f"websocket: ç”¨æˆ·: {user_id} å¼‚å¸¸é€€å‡º: {e}")
